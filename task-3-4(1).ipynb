{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12961420,"sourceType":"datasetVersion","datasetId":8203078}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-27T18:01:51.270278Z","iopub.execute_input":"2025-09-27T18:01:51.270501Z","iopub.status.idle":"2025-09-27T18:01:53.640621Z","shell.execute_reply.started":"2025-09-27T18:01:51.270482Z","shell.execute_reply":"2025-09-27T18:01:53.639558Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gdp-per-country-20202025/2020-2025.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = data[[\"Year\"]]\ny = data[\"Value\"]\n\n# 80% training, 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training set:\\n\", X_train)\nprint(\"Testing set:\\n\", X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T18:19:54.440276Z","iopub.execute_input":"2025-09-27T18:19:54.440854Z","iopub.status.idle":"2025-09-27T18:19:54.453058Z","shell.execute_reply.started":"2025-09-27T18:19:54.440829Z","shell.execute_reply":"2025-09-27T18:19:54.451822Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2529688386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Initialize and fit model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predictions\ny_pred = model.predict(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"MAE:\", mae)\nprint(\"MSE:\", mse)\nprint(\"RÂ²:\", r2)\nimport matplotlib.pyplot as plt\n\n# Predict on full dataset for regression line\ny_line = model.predict(X)\n\nplt.scatter(X, y, color=\"blue\", label=\"Actual Data\")\nplt.plot(X, y_line, color=\"red\", linewidth=2, label=\"Regression Line\")\n\nplt.xlabel(\"Year\")\nplt.ylabel(\"Value\")\nplt.title(f\"Linear Regression for {country}\")\nplt.legend()\nplt.show()\n\n# Interpret coefficients\nprint(\"Intercept:\", model.intercept_)\nprint(\"Coefficient:\", model.coef_[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Train logistic regression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train_scaled, y_train)\n\n# Predictions (class labels and probabilities)\ny_pred = log_reg.predict(X_test_scaled)\ny_prob = log_reg.predict_proba(X_test_scaled)[:,1]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# Classification report (precision, recall, F1)\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n\n# ROC-AUC\nroc_auc = roc_auc_score(y_test, y_prob)\nprint(\"ROC-AUC:\", roc_auc)\n\n# ROC Curve\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nplt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\nplt.plot([0,1],[0,1],'--',color=\"gray\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Default threshold = 0.5, let's try 0.6\nthreshold = 0.6\ny_pred_thresh = (y_prob >= threshold).astype(int)\n\nprint(\"Confusion Matrix (Threshold=0.6):\\n\", confusion_matrix(y_test, y_pred_thresh))\n\n# Sigmoid function example\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nexample_val = 2.0\nprint(\"Sigmoid(2.0):\", sigmoid(example_val))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}